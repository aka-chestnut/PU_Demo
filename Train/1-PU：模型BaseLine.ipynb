{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    }
   ],
   "source": [
    "from nezha import hiveDb\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import timeit\n",
    "import random\n",
    "from pyhive import hive\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from matplotlib.pylab import style\n",
    "style.use('ggplot')    \n",
    "plt.rcParams['font.sans-serif']=['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False  \n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 训练集：train.csv\n",
    "- 验证集1：before_val.csv\n",
    "- 验证集2：after_val.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为做 demo 二次筛选特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 37s, sys: 22.3 s, total: 3min 59s\n",
      "Wall time: 3min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data = pd.read_csv('new_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 13s, sys: 1.13 s, total: 1min 14s\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "null_list = train_data.isnull().sum() / len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_list = null_list[null_list>0.8].index.tolist()\n",
    "np.save('null_list_fornew.npy',null_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(null_list,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('train_drop0.8null.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1 = train_data[train_data['target']==1]\n",
    "train_data2 = train_data[train_data['target']==0].sample(n=20000,random_state=2020)\n",
    "del train_data\n",
    "import gc\n",
    "gc.collect()\n",
    "train_data = pd.concat([train_data1,train_data2])\n",
    "train_data.to_csv('sample_train20000_80.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_data1,train_data2\n",
    "X = train_data.drop('target',axis=1)\n",
    "y = train_data['target']\n",
    "del train_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = pd.read_csv('sample_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.4,random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ks_2samp\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "import time\n",
    "from pprint import pprint\n",
    "class XGBPipeline():\n",
    "    def __init__(self,X_train,X_test,y_train,y_test):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train       \n",
    "        self.X_test = X_test    \n",
    "        self.y_test = y_test\n",
    "    \n",
    "    def get_ks(self,y_true,y_pred):\n",
    "        return ks_2samp(y_pred[y_true==1], y_pred[y_true!=1]).statistic\n",
    "    \n",
    "    def timer (func):\n",
    "        def wrapper(*args,**kwargs): \n",
    "            start = time.time()\n",
    "            result = func(*args,**kwargs)\n",
    "            end = time.time()\n",
    "            print(func.__name__+'运行时间：','{:.2f}'.format(end-start))\n",
    "            return result\n",
    "        return wrapper\n",
    "    \n",
    "    @timer\n",
    "    def fit_baseline(self):\n",
    "        print(\"==========Model BaseLine Train==========\")\n",
    "        params={'booster':'gbtree',\n",
    "                'objective': 'binary:logistic',\n",
    "                'max_depth':5,\n",
    "                'subsample':0.8,\n",
    "                'colsample_bytree':0.8,\n",
    "                'min_child_weight':8,\n",
    "                'learning_rate ': 0.05,\n",
    "                'nthread':-1,\n",
    "                'n_estimators':100}\n",
    "        model = XGBClassifier(**params,verbosity=2)\n",
    "        print('start')\n",
    "        model.fit(self.X_train,self.y_train,verbose=True,eval_set=[(self.X_train,self.y_train)],eval_metric='auc')\n",
    "        self.model_evl(model)\n",
    "        \n",
    "    @timer\n",
    "    def train_model(self,params):\n",
    "        model = XGBClassifier(**params,verbosity=2)\n",
    "        model.fit(self.X_train,self.y_train,verbose=2)\n",
    "        self.model_evl(model)\n",
    "        return model\n",
    "        \n",
    "    @timer\n",
    "    def gridsearch_para(self):\n",
    "        params={'booster':'gbtree',\n",
    "                'objective': 'binary:logistic',\n",
    "                'max_depth':5,\n",
    "                'subsample':0.8,\n",
    "                'colsample_bytree':0.8,\n",
    "                'min_child_weight':8,\n",
    "                'learning_rate ': 0.005,\n",
    "                'nthread':-1,\n",
    "                'n_estimators':1000}\n",
    "        print(\"==========Optimize Parameters==========\")\n",
    "        print(\"n_estimators:\")\n",
    "        param_test1 = {'n_estimators':range(40,160,20)}\n",
    "        xgb = XGBClassifier(\n",
    "            **params,\n",
    "            scale_pos_weight=float(len(self.y_train.values)-np.sum(self.y_train.values))/float(np.sum(self.y_train.values)),\n",
    "            seed=2018,\n",
    "            silent=False)\n",
    "        gsearch1 = GridSearchCV(estimator = xgb, param_grid = param_test1, scoring='roc_auc',cv=5,n_jobs=-1)\n",
    "        gsearch1.fit(self.X_train,self.y_train)\n",
    "        print(gsearch1.best_params_,gsearch1.best_score_)\n",
    "        params.update(gsearch1.best_params_)\n",
    "        print(\"max_depth:\")\n",
    "        param_test2 = {'max_depth':range(3,7,1)}\n",
    "        xgb = XGBClassifier(\n",
    "            **params,\n",
    "            scale_pos_weight=float(len(self.y_train.values)-np.sum(self.y_train.values))/float(np.sum(self.y_train.values)),\n",
    "            seed=2018,\n",
    "            silent=False)\n",
    "        gsearch2 = GridSearchCV(estimator = xgb, param_grid = param_test2, scoring='roc_auc',cv=5,n_jobs=-1)\n",
    "        gsearch2.fit(self.X_train,self.y_train)\n",
    "        print(gsearch2.best_params_,gsearch2.best_score_)\n",
    "        params.update(gsearch2.best_params_)\n",
    "        print(\"min_child_weight:\")\n",
    "        param_test3 = {'min_child_weight':range(3,9,1)}\n",
    "        xgb = XGBClassifier(\n",
    "            **params,\n",
    "            scale_pos_weight=float(len(self.y_train.values)-np.sum(self.y_train.values))/float(np.sum(self.y_train.values)),\n",
    "            seed=2018,\n",
    "            silent=False)\n",
    "        gsearch3 = GridSearchCV(estimator = xgb, param_grid = param_test3, scoring='roc_auc',cv=5,n_jobs=-1)\n",
    "        gsearch3.fit(self.X_train,self.y_train)\n",
    "        print(gsearch3.best_params_,gsearch3.best_score_)\n",
    "        params.update(gsearch3.best_params_)\n",
    "        print(\"subsample:\")\n",
    "        param_test4 = {\n",
    "         'subsample':[i/10.0 for i in range(7,10,1)],\n",
    "        #  'colsample_bytree':[i/10.0 for i in range(6,10,1)]\n",
    "        }\n",
    "        xgb = XGBClassifier(\n",
    "            **params,\n",
    "            scale_pos_weight=float(len(self.y_train.values)-np.sum(self.y_train.values))/float(np.sum(self.y_train.values)),\n",
    "            seed=2018,\n",
    "            silent=False)\n",
    "        gsearch4 = GridSearchCV(estimator = xgb, param_grid = param_test4, scoring='roc_auc',cv=5,n_jobs=-1)\n",
    "        gsearch4.fit(self.X_train,self.y_train)\n",
    "        print(gsearch4.best_params_,gsearch4.best_score_)\n",
    "        params.update(gsearch4.best_params_)\n",
    "        print(\"colsample_bytree:\")\n",
    "        param_test5 = {\n",
    "          'colsample_bytree':[i/10.0 for i in range(7,10,1)]\n",
    "        }\n",
    "        xgb = XGBClassifier(\n",
    "            **params,\n",
    "            scale_pos_weight=float(len(self.y_train.values)-np.sum(self.y_train.values))/float(np.sum(self.y_train.values)),\n",
    "            seed=2018,\n",
    "            silent=False)\n",
    "        gsearch5 = GridSearchCV(estimator = xgb, param_grid = param_test5, scoring='roc_auc',cv=5,n_jobs=-1)\n",
    "        gsearch5.fit(self.X_train,self.y_train)\n",
    "        print(gsearch5.best_params_,gsearch5.best_score_)\n",
    "        params.update(gsearch5.best_params_)\n",
    "        print(\"调参结束后模型效果:\")\n",
    "        params.update({'scale_pos_weight':float(len(self.y_train.values)-np.sum(self.y_train.values))/float(np.sum(self.y_train.values)),\n",
    "            'seed':2018,\n",
    "            'silent':False})\n",
    "        return self.train_model(params)\n",
    "        \n",
    "    def model_evl(self,model):\n",
    "        print('模型评价：')\n",
    "        pred = model.predict_proba(self.X_test)\n",
    "        pred_y = pred[:,1]\n",
    "        print ('AUC: %.4f' % metrics.roc_auc_score(self.y_test,pred_y))\n",
    "        ypred = (pred_y>=0.5)*1 \n",
    "        print ('ACC: %.4f' % metrics.accuracy_score(self.y_test,ypred))\n",
    "        print ('Recall: %.4f' % metrics.recall_score(self.y_test,ypred))\n",
    "        print ('Precesion: %.4f' %metrics.precision_score(self.y_test,ypred))\n",
    "        print ('F1-score: %.4f' %metrics.f1_score(self.y_test,ypred))\n",
    "        print ('KS: %.4f' %self.get_ks(self.y_test,ypred))\n",
    "        print('\\n')\n",
    "        print(metrics.confusion_matrix(self.y_test,ypred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbp = XGBPipeline(X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Model BaseLine Train==========\n",
      "start\n",
      "[0]\tvalidation_0-auc:0.591305\n",
      "[1]\tvalidation_0-auc:0.606918\n",
      "[2]\tvalidation_0-auc:0.718001\n",
      "[3]\tvalidation_0-auc:0.723496\n",
      "[4]\tvalidation_0-auc:0.737984\n",
      "[5]\tvalidation_0-auc:0.73947\n",
      "[6]\tvalidation_0-auc:0.738943\n",
      "[7]\tvalidation_0-auc:0.750577\n",
      "[8]\tvalidation_0-auc:0.763221\n",
      "[9]\tvalidation_0-auc:0.762902\n",
      "[10]\tvalidation_0-auc:0.766776\n",
      "[11]\tvalidation_0-auc:0.769425\n",
      "[12]\tvalidation_0-auc:0.768791\n",
      "[13]\tvalidation_0-auc:0.772403\n",
      "[14]\tvalidation_0-auc:0.773784\n",
      "[15]\tvalidation_0-auc:0.771102\n",
      "[16]\tvalidation_0-auc:0.774837\n",
      "[17]\tvalidation_0-auc:0.78159\n",
      "[18]\tvalidation_0-auc:0.791779\n",
      "[19]\tvalidation_0-auc:0.810752\n",
      "[20]\tvalidation_0-auc:0.815685\n",
      "[21]\tvalidation_0-auc:0.814648\n",
      "[22]\tvalidation_0-auc:0.824995\n",
      "[23]\tvalidation_0-auc:0.828255\n",
      "[24]\tvalidation_0-auc:0.829746\n",
      "[25]\tvalidation_0-auc:0.844122\n",
      "[26]\tvalidation_0-auc:0.845126\n",
      "[27]\tvalidation_0-auc:0.852386\n",
      "[28]\tvalidation_0-auc:0.858539\n",
      "[29]\tvalidation_0-auc:0.864655\n",
      "[30]\tvalidation_0-auc:0.867362\n",
      "[31]\tvalidation_0-auc:0.877699\n",
      "[32]\tvalidation_0-auc:0.881149\n",
      "[33]\tvalidation_0-auc:0.887725\n",
      "[34]\tvalidation_0-auc:0.887677\n",
      "[35]\tvalidation_0-auc:0.892193\n",
      "[36]\tvalidation_0-auc:0.897823\n",
      "[37]\tvalidation_0-auc:0.901662\n",
      "[38]\tvalidation_0-auc:0.905915\n",
      "[39]\tvalidation_0-auc:0.910096\n",
      "[40]\tvalidation_0-auc:0.912554\n",
      "[41]\tvalidation_0-auc:0.91379\n",
      "[42]\tvalidation_0-auc:0.918511\n",
      "[43]\tvalidation_0-auc:0.920354\n",
      "[44]\tvalidation_0-auc:0.922572\n",
      "[45]\tvalidation_0-auc:0.924614\n",
      "[46]\tvalidation_0-auc:0.926159\n",
      "[47]\tvalidation_0-auc:0.928887\n",
      "[48]\tvalidation_0-auc:0.932499\n",
      "[49]\tvalidation_0-auc:0.934596\n",
      "[50]\tvalidation_0-auc:0.937542\n",
      "[51]\tvalidation_0-auc:0.940718\n",
      "[52]\tvalidation_0-auc:0.943184\n",
      "[53]\tvalidation_0-auc:0.944619\n",
      "[54]\tvalidation_0-auc:0.947093\n",
      "[55]\tvalidation_0-auc:0.948519\n",
      "[56]\tvalidation_0-auc:0.949745\n",
      "[57]\tvalidation_0-auc:0.951143\n",
      "[58]\tvalidation_0-auc:0.951177\n",
      "[59]\tvalidation_0-auc:0.951515\n",
      "[60]\tvalidation_0-auc:0.954999\n",
      "[61]\tvalidation_0-auc:0.956297\n",
      "[62]\tvalidation_0-auc:0.957304\n",
      "[63]\tvalidation_0-auc:0.958732\n",
      "[64]\tvalidation_0-auc:0.961172\n",
      "[65]\tvalidation_0-auc:0.962204\n",
      "[66]\tvalidation_0-auc:0.963259\n",
      "[67]\tvalidation_0-auc:0.9647\n",
      "[68]\tvalidation_0-auc:0.966537\n",
      "[69]\tvalidation_0-auc:0.968084\n",
      "[70]\tvalidation_0-auc:0.969262\n",
      "[71]\tvalidation_0-auc:0.969469\n",
      "[72]\tvalidation_0-auc:0.970776\n",
      "[73]\tvalidation_0-auc:0.971071\n",
      "[74]\tvalidation_0-auc:0.972224\n",
      "[75]\tvalidation_0-auc:0.971943\n",
      "[76]\tvalidation_0-auc:0.972879\n",
      "[77]\tvalidation_0-auc:0.974756\n",
      "[78]\tvalidation_0-auc:0.976021\n",
      "[79]\tvalidation_0-auc:0.976215\n",
      "[80]\tvalidation_0-auc:0.976797\n",
      "[81]\tvalidation_0-auc:0.97799\n",
      "[82]\tvalidation_0-auc:0.978935\n",
      "[83]\tvalidation_0-auc:0.979423\n",
      "[84]\tvalidation_0-auc:0.979731\n",
      "[85]\tvalidation_0-auc:0.980045\n",
      "[86]\tvalidation_0-auc:0.980528\n",
      "[87]\tvalidation_0-auc:0.981074\n",
      "[88]\tvalidation_0-auc:0.981648\n",
      "[89]\tvalidation_0-auc:0.982118\n",
      "[90]\tvalidation_0-auc:0.982373\n",
      "[91]\tvalidation_0-auc:0.982692\n",
      "[92]\tvalidation_0-auc:0.982627\n",
      "[93]\tvalidation_0-auc:0.983176\n",
      "[94]\tvalidation_0-auc:0.983638\n",
      "[95]\tvalidation_0-auc:0.984358\n",
      "[96]\tvalidation_0-auc:0.984913\n",
      "[97]\tvalidation_0-auc:0.985376\n",
      "[98]\tvalidation_0-auc:0.985849\n",
      "[99]\tvalidation_0-auc:0.986339\n",
      "模型评价：\n",
      "AUC: 0.8145\n",
      "ACC: 0.9869\n",
      "Recall: 0.0641\n",
      "Precesion: 0.9000\n",
      "F1-score: 0.1196\n",
      "KS: 0.0640\n",
      "\n",
      "\n",
      "[[20013     2]\n",
      " [  263    18]]\n",
      "fit_baseline运行时间： 237.61\n"
     ]
    }
   ],
   "source": [
    "xgbp.fit_baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========Optimize Parameters==========\n",
      "n_estimators:\n",
      "{'n_estimators': 140} 0.7794763248524861\n",
      "max_depth:\n",
      "{'max_depth': 5} 0.7794763248524861\n",
      "min_child_weight:\n",
      "{'min_child_weight': 3} 0.7706818554555852\n",
      "subsample:\n",
      "{'subsample': 0.9} 0.7759738434051251\n",
      "colsample_bytree:\n",
      "{'colsample_bytree': 0.7} 0.7794647841963543\n",
      "调参结束后模型效果:\n",
      "模型评价：\n",
      "AUC: 0.7878\n",
      "ACC: 0.9607\n",
      "Recall: 0.2986\n",
      "Precesion: 0.3879\n",
      "F1-score: 0.3374\n",
      "KS: 0.2822\n",
      "\n",
      "\n",
      "[[7887  131]\n",
      " [ 195   83]]\n",
      "train_model运行时间： 101.95\n",
      "gridsearch_para运行时间： 1330.88\n"
     ]
    }
   ],
   "source": [
    "xgbp.gridsearch_para()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
